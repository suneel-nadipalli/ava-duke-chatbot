{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-16T21:34:18.631512Z","iopub.status.busy":"2024-04-16T21:34:18.631271Z","iopub.status.idle":"2024-04-16T21:39:37.049612Z","shell.execute_reply":"2024-04-16T21:39:37.048518Z","shell.execute_reply.started":"2024-04-16T21:34:18.631489Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Installed PIP\n","Installed Transformers\n","Installed Torch\n","Installed PEFT\n","Installed Accelerate\n","Installed LoRA Lib\n","Installed BitsAndBytes\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf 23.8.0 requires cubinlinker, which is not installed.\n","cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","cudf 23.8.0 requires ptxcompiler, which is not installed.\n","cuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","dask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\n","apache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\n","apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 15.0.2 which is incompatible.\n","cudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.4.0 which is incompatible.\n","cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\n","cudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\n","cudf 23.8.0 requires pyarrow==11.*, but you have pyarrow 15.0.2 which is incompatible.\n","cuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.0 which is incompatible.\n","dask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.0 which is incompatible.\n","dask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\n","dask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.0 which is incompatible.\n","dask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\n","distributed 2023.7.1 requires dask==2023.7.1, but you have dask 2024.4.0 which is incompatible.\n","pathos 0.3.2 requires dill>=0.3.8, but you have dill 0.3.7 which is incompatible.\n","pathos 0.3.2 requires multiprocess>=0.70.16, but you have multiprocess 0.70.15 which is incompatible.\n","raft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.0 which is incompatible.\n","s3fs 2024.2.0 requires fsspec==2024.2.0, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mInstalled Datasets\n"]}],"source":["!pip install -Uqqq pip --progress-bar off\n","print(\"Installed PIP\")\n","!pip install -Uqqq git+https://github.com/huggingface/transformers\n","print(\"Installed Transformers\")\n","!pip install -Uqqq torch torchvision\n","print(\"Installed Torch\")\n","!pip install -qqq -U peft\n","print(\"Installed PEFT\")\n","!pip install -Uqqq accelerate\n","print(\"Installed Accelerate\")\n","!pip install -qqq loralib==0.1.1 --progress-bar off\n","!pip install -qqq einops==0.6.1 --progress-bar off\n","print(\"Installed LoRA Lib\")\n","!pip install -qqq bitsandbytes\n","print(\"Installed BitsAndBytes\")\n","!pip install fsspec -qqq\n","\n","!pip install datasets==2.16.0 fsspec==2023.10.0 gcsfs==2023.10.0 -qqq\n","print(\"Installed Datasets\")"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T21:39:37.052059Z","iopub.status.busy":"2024-04-16T21:39:37.051776Z","iopub.status.idle":"2024-04-16T21:39:49.089159Z","shell.execute_reply":"2024-04-16T21:39:49.087914Z","shell.execute_reply.started":"2024-04-16T21:39:37.052030Z"},"trusted":true},"outputs":[],"source":["!pip install huggingface_hub -qqq"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T21:39:49.091266Z","iopub.status.busy":"2024-04-16T21:39:49.090847Z","iopub.status.idle":"2024-04-16T21:39:56.371088Z","shell.execute_reply":"2024-04-16T21:39:56.370162Z","shell.execute_reply.started":"2024-04-16T21:39:49.091227Z"},"trusted":true},"outputs":[],"source":["import json\n","import os\n","from pprint import pprint\n","import bitsandbytes as bnb\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import transformers\n","from datasets import load_dataset\n","from huggingface_hub import notebook_login\n","\n","from peft import (\n","    LoraConfig,\n","    PeftConfig,\n","    PeftModel,\n","    get_peft_model,\n","    prepare_model_for_kbit_training,\n",")\n","\n","from transformers import (\n","    AutoConfig,\n","    AutoModelForCausalLM,\n","    AutoTokenizer,\n","    BitsAndBytesConfig  \n",")"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T21:39:56.373097Z","iopub.status.busy":"2024-04-16T21:39:56.372444Z","iopub.status.idle":"2024-04-16T21:41:23.395751Z","shell.execute_reply":"2024-04-16T21:41:23.394816Z","shell.execute_reply.started":"2024-04-16T21:39:56.373069Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"842fdadcfecf432d9317440bca16a0a7","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b728b31edf6b4676997385c7f7581e9d","version_major":2,"version_minor":0},"text/plain":["model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"90e2024b587d46f99fcb34b67783dfe4","version_major":2,"version_minor":0},"text/plain":["Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"65446308de604e248b51c053fa4d28f8","version_major":2,"version_minor":0},"text/plain":["model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"609640a626494a038eb5cbfcc0393531","version_major":2,"version_minor":0},"text/plain":["model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"98baf97ab78b426a8f31543cea9d99e3","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"16ee13c89121446dbd61203c0595d631","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"878a93cec16c444c924f49566347d071","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ab3ff56465a8410da988117c2e90f582","version_major":2,"version_minor":0},"text/plain":["tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"47e693146ab343e291aa4dfc699a89d2","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9a94a8ec64284b8f812ddb2661759d7c","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["MODEL_NAME = \"mistralai/Mistral-7B-v0.1\"\n","\n","bnb_config = BitsAndBytesConfig(\n","   load_in_4bit=True,\n","   bnb_4bit_quant_type=\"nf4\",\n","   bnb_4bit_use_double_quant=True,\n","   bnb_4bit_compute_dtype=torch.bfloat16\n",")\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    MODEL_NAME,\n","    device_map='auto',\n","    quantization_config=bnb_config,\n","    use_cache=False,\n","    trust_remote_code=True\n",")\n","\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","\n","tokenizer.pad_token = tokenizer.eos_token"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T21:41:23.398387Z","iopub.status.busy":"2024-04-16T21:41:23.398074Z","iopub.status.idle":"2024-04-16T21:41:23.403982Z","shell.execute_reply":"2024-04-16T21:41:23.403064Z","shell.execute_reply.started":"2024-04-16T21:41:23.398360Z"},"trusted":true},"outputs":[],"source":["def print_trainable_parameters(model):\n","    trainable_params = 0\n","    all_param = 0\n","    for _, param in model.named_parameters():\n","        all_param += param.numel()\n","        \n","        if param.requires_grad:\n","            trainable_params += param.numel()\n","    \n","    print(\n","        f\"Trainable params: {trainable_params} || All params: {all_param} || trainable %: {100* trainable_params/all_param}\"\n","    )"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T21:41:23.405695Z","iopub.status.busy":"2024-04-16T21:41:23.405359Z","iopub.status.idle":"2024-04-16T21:41:23.452401Z","shell.execute_reply":"2024-04-16T21:41:23.451726Z","shell.execute_reply.started":"2024-04-16T21:41:23.405663Z"},"trusted":true},"outputs":[],"source":["model.gradient_checkpointing_enable()\n","model = prepare_model_for_kbit_training(model)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T21:41:23.453669Z","iopub.status.busy":"2024-04-16T21:41:23.453386Z","iopub.status.idle":"2024-04-16T21:41:23.636043Z","shell.execute_reply":"2024-04-16T21:41:23.635165Z","shell.execute_reply.started":"2024-04-16T21:41:23.453644Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Trainable params: 6815744 || All params: 3758886912 || trainable %: 0.18132346515244138\n"]}],"source":["config = LoraConfig(\n","    r=16,\n","    lora_alpha=32,\n","#     target_modules=['query_key_value'],\n","    lora_dropout=0.05,\n","    bias='none',\n","    task_type='CAUSAL_LM'\n",")\n","\n","model = get_peft_model(model, config)\n","print_trainable_parameters(model)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T21:41:23.637807Z","iopub.status.busy":"2024-04-16T21:41:23.637461Z","iopub.status.idle":"2024-04-16T21:41:23.642731Z","shell.execute_reply":"2024-04-16T21:41:23.641747Z","shell.execute_reply.started":"2024-04-16T21:41:23.637776Z"},"trusted":true},"outputs":[],"source":["gen_config = model.generation_config\n","gen_config.max_new_tokens = 200\n","gen_config.temperature = 0.7\n","gen_config.top_p = 0.7\n","gen_config.num_return_sequences = 1\n","gen_config.pad_token_id = tokenizer.eos_token_id\n","gen_config.eos_token_id = tokenizer.eos_token_id"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T21:41:30.807990Z","iopub.status.busy":"2024-04-16T21:41:30.806605Z","iopub.status.idle":"2024-04-16T21:41:34.484073Z","shell.execute_reply":"2024-04-16T21:41:34.483220Z","shell.execute_reply.started":"2024-04-16T21:41:30.807943Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"790bcc28964c41619dcf89fb721b4731","version_major":2,"version_minor":0},"text/plain":["Downloading readme:   0%|          | 0.00/442 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"645e5888eb4245a8afa1f47e8ca0b885","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/1.16M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0fdb1ec992fe4375a305ad65e692538f","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/309k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c46406ec39f944eda1ceebd1233bf2f2","version_major":2,"version_minor":0},"text/plain":["Generating train split:   0%|          | 0/559 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"22ae606f6d4f4b9895cd181cd60f613f","version_major":2,"version_minor":0},"text/plain":["Generating val split:   0%|          | 0/140 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from datasets import load_dataset\n","\n","qa_dataset = load_dataset(\"suneeln-duke/duke_qac_v3\")"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T21:41:36.643961Z","iopub.status.busy":"2024-04-16T21:41:36.642844Z","iopub.status.idle":"2024-04-16T21:41:36.653577Z","shell.execute_reply":"2024-04-16T21:41:36.652335Z","shell.execute_reply.started":"2024-04-16T21:41:36.643909Z"},"trusted":true},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['Question', 'Context', 'Answer'],\n","        num_rows: 559\n","    })\n","    val: Dataset({\n","        features: ['Question', 'Context', 'Answer'],\n","        num_rows: 140\n","    })\n","})"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["qa_dataset"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T21:41:37.370092Z","iopub.status.busy":"2024-04-16T21:41:37.369735Z","iopub.status.idle":"2024-04-16T21:41:37.376271Z","shell.execute_reply":"2024-04-16T21:41:37.375242Z","shell.execute_reply.started":"2024-04-16T21:41:37.370063Z"},"trusted":true},"outputs":[],"source":["def generate_prompt(data_point):\n","    \n","    \"\"\"\"\n","    Update the prompt template:\n","    Combine both the prompt and input into a single column.\n","\n","    \"\"\"     \n","    bos_token = \"<s>\"\n","    \n","    original_system_message = \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\"\n","    \n","    system_message = \"Use the provided context followed by a question to answer it.\"\n","    \n","    full_prompt = f\"\"\"<s>### Instruction:\n","    {system_message}\n","    \n","    ### Context:\n","    {data_point['Context']}\n","    \n","    \n","    ### Question:\n","    \n","    {data_point['Question']}\n","    \n","    \n","    ### Aswer: \n","    {data_point['Answer']}\n","    \"\"\"\n","    \n","    full_prompt = \" \".join(full_prompt.split())\n","    \n","    return full_prompt"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T21:41:39.058028Z","iopub.status.busy":"2024-04-16T21:41:39.057113Z","iopub.status.idle":"2024-04-16T21:41:39.062823Z","shell.execute_reply":"2024-04-16T21:41:39.061877Z","shell.execute_reply.started":"2024-04-16T21:41:39.057991Z"},"trusted":true},"outputs":[],"source":["def generate_and_tokenize_prompt(data_point):\n","    \n","    full_prompt = generate_prompt(data_point)\n","    \n","    tokenized_full_prompt = tokenizer(full_prompt, padding=True, truncation=True)\n","    \n","    return tokenized_full_prompt"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T21:41:45.024959Z","iopub.status.busy":"2024-04-16T21:41:45.024345Z","iopub.status.idle":"2024-04-16T21:41:48.256576Z","shell.execute_reply":"2024-04-16T21:41:48.255582Z","shell.execute_reply.started":"2024-04-16T21:41:45.024918Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"67b1d89cc0034a19b2fd0408fc4d1502","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/559 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"938a09bfca1d44e2b04f9debcfad8948","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/140 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["train_dataset = qa_dataset[\"train\"].shuffle().map(generate_and_tokenize_prompt)\n","val_dataset = qa_dataset[\"val\"].shuffle().map(generate_and_tokenize_prompt)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T21:41:55.932012Z","iopub.status.busy":"2024-04-16T21:41:55.931061Z","iopub.status.idle":"2024-04-16T21:41:55.936056Z","shell.execute_reply":"2024-04-16T21:41:55.934957Z","shell.execute_reply.started":"2024-04-16T21:41:55.931974Z"},"trusted":true},"outputs":[],"source":["OUTPUT_DIR = \"experiments\""]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T21:41:56.344324Z","iopub.status.busy":"2024-04-16T21:41:56.343952Z","iopub.status.idle":"2024-04-16T21:41:56.350272Z","shell.execute_reply":"2024-04-16T21:41:56.349300Z","shell.execute_reply.started":"2024-04-16T21:41:56.344297Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['Question', 'Context', 'Answer', 'input_ids', 'attention_mask'],\n","    num_rows: 559\n","})"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["train_dataset"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T21:41:57.327091Z","iopub.status.busy":"2024-04-16T21:41:57.326723Z","iopub.status.idle":"2024-04-16T21:41:57.389593Z","shell.execute_reply":"2024-04-16T21:41:57.388811Z","shell.execute_reply.started":"2024-04-16T21:41:57.327060Z"},"trusted":true},"outputs":[],"source":["training_args = transformers.TrainingArguments(\n","    per_device_train_batch_size = 1,\n","    gradient_accumulation_steps = 4,\n","    num_train_epochs = 1,\n","    learning_rate = 2e-4,\n","    fp16 = True,\n","    save_total_limit = 3,\n","    logging_steps = 10,\n","    output_dir = OUTPUT_DIR,\n","    max_steps = 200,\n","    optim = \"paged_adamw_8bit\",\n","    lr_scheduler_type = \"cosine\",\n","    warmup_ratio = 0.05,\n",")"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T21:41:59.342567Z","iopub.status.busy":"2024-04-16T21:41:59.342229Z","iopub.status.idle":"2024-04-16T21:42:10.765712Z","shell.execute_reply":"2024-04-16T21:42:10.764834Z","shell.execute_reply.started":"2024-04-16T21:41:59.342540Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-04-16 21:42:02.014806: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-04-16 21:42:02.014930: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-04-16 21:42:02.166363: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","max_steps is given, it will override any value given in num_train_epochs\n"]}],"source":["trainer = transformers.Trainer(\n","    model = model,\n","    train_dataset = train_dataset,\n","    eval_dataset = val_dataset,\n","    args = training_args,\n","    data_collator = transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",")"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T21:42:13.636793Z","iopub.status.busy":"2024-04-16T21:42:13.635837Z","iopub.status.idle":"2024-04-16T22:53:29.391260Z","shell.execute_reply":"2024-04-16T22:53:29.390377Z","shell.execute_reply.started":"2024-04-16T21:42:13.636749Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  ········································\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/html":["wandb version 0.16.6 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.5"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20240416_214303-q52lb9uq</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/n-suneel-duke/huggingface/runs/q52lb9uq/workspace' target=\"_blank\">prime-salad-18</a></strong> to <a href='https://wandb.ai/n-suneel-duke/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/n-suneel-duke/huggingface' target=\"_blank\">https://wandb.ai/n-suneel-duke/huggingface</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/n-suneel-duke/huggingface/runs/q52lb9uq/workspace' target=\"_blank\">https://wandb.ai/n-suneel-duke/huggingface/runs/q52lb9uq/workspace</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [200/200 1:09:47, Epoch 1/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>1.512700</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>1.335300</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>1.166200</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>1.056800</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.914500</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.693100</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.630400</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.493000</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.514600</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.393200</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.341100</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.304800</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.283200</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.225800</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.217600</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.214400</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.201700</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.193700</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.213200</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.200000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=200, training_loss=0.5552666527032852, metrics={'train_runtime': 4275.4145, 'train_samples_per_second': 0.187, 'train_steps_per_second': 0.047, 'total_flos': 4.805090502303744e+16, 'train_loss': 0.5552666527032852, 'epoch': 1.4311270125223614})"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["model.config_use_cache = False\n","\n","trainer.train()"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T23:06:07.520474Z","iopub.status.busy":"2024-04-16T23:06:07.519374Z","iopub.status.idle":"2024-04-16T23:06:07.866043Z","shell.execute_reply":"2024-04-16T23:06:07.865013Z","shell.execute_reply.started":"2024-04-16T23:06:07.520418Z"},"trusted":true},"outputs":[],"source":["model.save_pretrained(\"duke_qac_ft_v3\")"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T23:06:13.019896Z","iopub.status.busy":"2024-04-16T23:06:13.019039Z","iopub.status.idle":"2024-04-16T23:06:13.049509Z","shell.execute_reply":"2024-04-16T23:06:13.048465Z","shell.execute_reply.started":"2024-04-16T23:06:13.019862Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"caa1d483e77d425493cd377e0f51e43e","version_major":2,"version_minor":0},"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"]},"metadata":{},"output_type":"display_data"}],"source":["from huggingface_hub import notebook_login\n","import huggingface_hub\n","\n","notebook_login()"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T23:06:19.463796Z","iopub.status.busy":"2024-04-16T23:06:19.463092Z","iopub.status.idle":"2024-04-16T23:06:19.688213Z","shell.execute_reply":"2024-04-16T23:06:19.687295Z","shell.execute_reply.started":"2024-04-16T23:06:19.463762Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n","Token is valid (permission: write).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]}],"source":["huggingface_hub.login(token='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')"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T23:06:28.461296Z","iopub.status.busy":"2024-04-16T23:06:28.460522Z","iopub.status.idle":"2024-04-16T23:06:32.017126Z","shell.execute_reply":"2024-04-16T23:06:32.016168Z","shell.execute_reply.started":"2024-04-16T23:06:28.461262Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:834: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9a983919579249b8a6e952cfcf30c37f","version_major":2,"version_minor":0},"text/plain":["README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"db121e6074f44ac69e9ba31994cbf25b","version_major":2,"version_minor":0},"text/plain":["adapter_model.safetensors:   0%|          | 0.00/27.3M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["CommitInfo(commit_url='https://huggingface.co/suneeln-duke/dukebot-qac-v2/commit/89288d21b6382e3ebb209c18bd00b96783be3421', commit_message='Upload model', commit_description='', oid='89288d21b6382e3ebb209c18bd00b96783be3421', pr_url=None, pr_revision=None, pr_num=None)"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["model.push_to_hub(\n","    \"suneeln-duke/dukebot-qac-v2\",\n","    use_auth_token=True\n",")"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T23:06:51.966522Z","iopub.status.busy":"2024-04-16T23:06:51.966140Z","iopub.status.idle":"2024-04-16T23:07:09.795545Z","shell.execute_reply":"2024-04-16T23:07:09.794476Z","shell.execute_reply.started":"2024-04-16T23:06:51.966494Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"704cebe640c74656b520d911498ff141","version_major":2,"version_minor":0},"text/plain":["adapter_config.json:   0%|          | 0.00/651 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9f66ca7063124d8ead624baca464576c","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["PEFT_MODEL = \"suneeln-duke/dukebot-qac-v2\"\n","\n","dtype = torch.bfloat16 if torch.cuda.get_device_capability()[0] == 8 else torch.float16\n","\n","config = PeftConfig.from_pretrained(PEFT_MODEL)\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    config.base_model_name_or_path,\n","    return_dict = True,\n","    quantization_config = bnb_config,\n","    device_map = \"auto\",\n","    torch_dtype = dtype,\n","    trust_remote_code = True\n",")"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T23:07:17.419752Z","iopub.status.busy":"2024-04-16T23:07:17.419374Z","iopub.status.idle":"2024-04-16T23:07:17.570752Z","shell.execute_reply":"2024-04-16T23:07:17.569610Z","shell.execute_reply.started":"2024-04-16T23:07:17.419720Z"},"trusted":true},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n","tokenizer.pad_token = tokenizer.eos_token"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T23:07:18.734821Z","iopub.status.busy":"2024-04-16T23:07:18.734161Z","iopub.status.idle":"2024-04-16T23:07:20.414562Z","shell.execute_reply":"2024-04-16T23:07:20.413482Z","shell.execute_reply.started":"2024-04-16T23:07:18.734787Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2c3ab891e856443980bb853dd8f08169","version_major":2,"version_minor":0},"text/plain":["adapter_model.safetensors:   0%|          | 0.00/27.3M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["model = PeftModel.from_pretrained(model, PEFT_MODEL)"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T23:07:20.416818Z","iopub.status.busy":"2024-04-16T23:07:20.416444Z","iopub.status.idle":"2024-04-16T23:07:21.895718Z","shell.execute_reply":"2024-04-16T23:07:21.894613Z","shell.execute_reply.started":"2024-04-16T23:07:20.416782Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n","  warnings.warn(\n"]}],"source":["model = model.merge_and_unload()"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T23:08:12.129126Z","iopub.status.busy":"2024-04-16T23:08:12.128475Z","iopub.status.idle":"2024-04-16T23:10:12.051774Z","shell.execute_reply":"2024-04-16T23:10:12.048260Z","shell.execute_reply.started":"2024-04-16T23:08:12.129084Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:834: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"83487fdc9f8c4bc6940c278a0c6f418e","version_major":2,"version_minor":0},"text/plain":["README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8d5fb08fc1b5462882d9d4665e3770f9","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/4.13G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["CommitInfo(commit_url='https://huggingface.co/suneeln-duke/dukebot-qac-v1-merged/commit/5a06d1bfe094d57a2ee5d91b1251751a0948c1a5', commit_message='Upload MistralForCausalLM', commit_description='', oid='5a06d1bfe094d57a2ee5d91b1251751a0948c1a5', pr_url=None, pr_revision=None, pr_num=None)"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["model.push_to_hub(\n","    \"suneeln-duke/dukebot-qac-v1-merged\",\n","    use_auth_token=True\n",")"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T23:10:16.591703Z","iopub.status.busy":"2024-04-16T23:10:16.590957Z","iopub.status.idle":"2024-04-16T23:10:18.411500Z","shell.execute_reply":"2024-04-16T23:10:18.410598Z","shell.execute_reply.started":"2024-04-16T23:10:16.591667Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:834: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n","  warnings.warn(\n"]},{"data":{"text/plain":["CommitInfo(commit_url='https://huggingface.co/suneeln-duke/dukebot-qac-v1-merged/commit/b70688c4caa85a88c17d2d24a1e367b0f446e936', commit_message='Upload tokenizer', commit_description='', oid='b70688c4caa85a88c17d2d24a1e367b0f446e936', pr_url=None, pr_revision=None, pr_num=None)"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","\n","tokenizer.push_to_hub(\n","    \"suneeln-duke/dukebot-qac-v1-merged\",\n","    use_auth_token=True\n",")"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-04-15T01:39:50.485668Z","iopub.status.busy":"2024-04-15T01:39:50.484749Z","iopub.status.idle":"2024-04-15T01:39:50.492538Z","shell.execute_reply":"2024-04-15T01:39:50.491785Z","shell.execute_reply.started":"2024-04-15T01:39:50.485615Z"},"trusted":true},"outputs":[],"source":["def generate_prompt_test(data_point):\n","    \n","    \"\"\"\"\n","    Update the prompt template:\n","    Combine both the prompt and input into a single column.\n","\n","    \"\"\"            \n","    bos_token = \"<s>\"\n","    \n","    original_system_message = \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\"\n","    \n","    system_message = \"Use the provided context followed by a question to answer it.\"\n","    \n","    full_prompt = f\"\"\"<s>### Instruction:\n","    {system_message}\n","    \n","    ### Context:\n","    {data_point['Context']}\n","    \n","    \n","    ### Question:\n","    \n","    {data_point['Question']}\n","    \n","    \n","    ### Aswer: \n","    \"\"\"\n","    \n","    full_prompt = \" \".join(full_prompt.split())\n","    \n","    return full_prompt"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-04-15T01:39:52.083588Z","iopub.status.busy":"2024-04-15T01:39:52.082702Z","iopub.status.idle":"2024-04-15T01:39:52.088674Z","shell.execute_reply":"2024-04-15T01:39:52.087893Z","shell.execute_reply.started":"2024-04-15T01:39:52.083554Z"},"trusted":true},"outputs":[],"source":["sample = qa_dataset['val'][5]"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-04-15T01:39:53.292101Z","iopub.status.busy":"2024-04-15T01:39:53.291336Z","iopub.status.idle":"2024-04-15T01:39:53.296880Z","shell.execute_reply":"2024-04-15T01:39:53.296073Z","shell.execute_reply.started":"2024-04-15T01:39:53.292068Z"},"trusted":true},"outputs":[],"source":["DEVICE = 'cuda:0'"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2024-04-15T01:39:55.263260Z","iopub.status.busy":"2024-04-15T01:39:55.262620Z","iopub.status.idle":"2024-04-15T01:40:23.601180Z","shell.execute_reply":"2024-04-15T01:40:23.600192Z","shell.execute_reply.started":"2024-04-15T01:39:55.263229Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:497: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n","  warnings.warn(\n"]}],"source":["%%time\n","\n","encoding = tokenizer(generate_prompt_test(sample), return_tensors='pt').to(DEVICE)\n","\n","with torch.inference_mode():\n","    outputs = model.generate(\n","        input_ids = encoding.input_ids,\n","        attention_mask = encoding.attention_mask,\n","        generation_config = gen_config\n","    )\n","    \n","resp = tokenizer.decode(outputs[0], skip_special_tokens=True)"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-04-15T01:40:29.707341Z","iopub.status.busy":"2024-04-15T01:40:29.706978Z","iopub.status.idle":"2024-04-15T01:40:29.714467Z","shell.execute_reply":"2024-04-15T01:40:29.713669Z","shell.execute_reply.started":"2024-04-15T01:40:29.707313Z"},"trusted":true},"outputs":[{"data":{"text/plain":["\"### Instruction: Use the provided context followed by a question to answer it. ### Context: engage directly with representatives from their company partner organization as well as receive guidance from Duke faculty members over the course of the project. The team will present their final deliverables to a sponsor panel and/or an external review panel. MENG 550: Master of Engineering Internship or Project- Internships are typically 8-12 weeks. The minimum hourly requirement for the internship is 320 hours, equivalent to 8 weeks, 40 hours per week. Projects require approval from the AIPI program director. Projects must fulfill the same learning objectives as internships. Although students are responsible for finding their own internship, Duke provides an experienced career development team to help with your search. All internships/projects must: Apply engineering principles to solving one or more problems outside the classroom environment Define a problem and determine potential solutions Appreciate the importance of organizational dynamics and work relationships Practice professional communication both written and orally Complement material presented in the AIPI courses Include a self-assessment upon completion in AIPI 551 MENG 551: Master of Engineering Internship or Project Assessment- This assessment course is the culmination of your internship or project work. You will prepare a substantive assessment of your internship or project experience via a written report and/or oral presentation. A polished analysis should include: Problem or task conducted Challenges faced Solutions incorporated Workplace communication and interpersonal relationship critique Individual performance review The Duke Difference: AI and Machine Learning WHY JOIN DUKE AI? Duke's AI Master of Engineering develops technical leaders who are equipped to build our Deep Learning Applications AIPI 549: Industry Capstone Project Technical Elective 1 Summer - AIPI 560: Legal, Societal & Ethical Implications of AI AIPI 561: Operationalizing AI (MLOps) Industry Internship or Project Fall 2- AIPI Departmental Elective Technical Elective 2 DEGREE REQUIREMENTS Pre-Program Bootcamp Summer Online Python & Data Science Math Boot Camp More » 10 Courses Four (4) Technical AI/ML courses—a strong technical foundation Three (3) Product Development courses—developed with Duke's Law School and Fuqua School of Business including the business, legal & ethical aspects of AI products Three (3) Technical electives—specialize in preparation for your chosen career Browse course descriptions » 2 Industry Experiences Industry project—design a solution to an authentic opportunity offered by a sponsoring organization A summer internship or industry project—gain industry experience More » Additional Requirements Learn from leaders building AI products during regular industry seminars Jump-start your professional development with our Career Strategy and Design workshop for on-campus students Meet peers and faculty during two (2) required residencies on the Duke campus for online students The choice of online or on-campus is up to you—all students take the same courses, learn from the same faculty, and earn the same Duke degree. COMPARE ONLINE AND ON-CAMPUS Online(part-time): - Time to Degree: 24 months - Python & Data Science Math Boot Camp: online 4-week part-time - Class Experience: live and recorded classes - Class Experience: online interaction with peers and faculty - Professional Development: two spring residences on campus at Duke - Professional Development: industry seminar series cultivate a diverse group of students passionate about several different fields and industries. Roughly half of our students join the program directly after their undergraduate studies, and the other half join after gaining work experience. Many students enter the program with a strong prior background in programming or software development, while others enter with less programming experience but stronger domain-specific expertise. The unique design of our program accommodates both types of participants. Browse student profiles: Eduardo Martinez, Class of 2022 Shyamal Anadkat, Class of 2022 Christine Park & Miranda Morris, Barr-Spach Scholarship Recipients, Class of 2022 AN INTERDISCIPLINARY EXPERIENCE At Duke Engineering, technical training is combined with management courses, industry seminars, a real-world capstone project and an industry internship to provide a well-rounded educational experience that develops both the hard skills and soft skills needed to succeed. Explore the Curriculum » A FLEXIBLE DEGREE DESIGNED FOR YOU On-campus or online Duke has you covered: Study on-campus or online. Start with the summer pre-program online data science and programming boot camp. Finish in as little as 12 months of full-time study through the accelerated course schedule, or stay for a third semester and focus on industry-oriented electives. Browse course descriptions » PARTNERED WITH INDUSTRY Duke's AI curriculum was created from scratch and designed with heavy input from AI leaders across industries. Our faculty come with experience at the top of the tech industry and in successful startups prior to joining Duke. We work closely with industry partners who provide real-world examples of High-Tech Industries- The purpose of this course is to empower students to become collaborative, ethical leaders in the globalized, 21st-century workplace. Students learn concepts and practice skills that will enable them to transition from being an engineering sole contributor to managing and leading others as a business professional. Students gain a sound understanding of management and leadership; increase awareness of their own management and leadership styles; build and practice competencies essential for team success (e.g., effective communication, collaboration, conflict resolution); and become ethical leaders above reproach. Emphasis is on leading teams in a volatile, complex and interdependent world. MENG 570: Business Fundamentals for Engineers- This comprehensive course examines core and evolving concepts in the business fundamentals of successful technology-based companies including Business Plan Development & Strategies, Marketing, Product & Process Development processes, Intellectual Property, Accounting, Finance, and Operations. Students will learn the fundamentals essential to understanding all aspects of a business and will be able to converse in some depth in each of the areas studied upon completion. Other topics will include Supply Chain Management, Stage-Gate Development Cycles, Balances Scorecards, Blue Ocean Strategy, and Disruptive Technologies. AIPI 530: Optimization in Practice- Optimization is the ultimate skill in artificial intelligence and prescriptive analytics allowing practitioners to generate the best actionable solutions for business needs. This class will give students required skills to mathematically formulate relevant business problems as optimization models, use leading software modeling syntax and solvers to generate optimum solutions and meaningfully interpret these solutions. We will use both data. AIPI 501: Industry Seminar Series- Students will attend a weekly seminar series featuring industry leaders discussing the opportunities, challenges and learnings they have gained from applying AI to products and services in their industry. Speakers will present live in-classroom or via video conference. The emphasis in the selection of speakers will be placed on representing more traditional industries that are poised to be disrupted by AI such as agriculture, health care/biotech, energy and environment, and manufacturing. The seminar series will reinforce the concepts learned in the core courses and expand students’ intuition for the opportunities to apply AI within more complex and/or traditional industries. AIPI 560: Legal, Societal & Ethical Implications of AI- Deploying AI within products and services has implications well beyond the technical considerations, which often include change management of operational workflows or staffing levels, data privacy considerations, bias risks and other ethical implications, and industry-specific regulations on the use of data and models operationally. This course will introduce students to the key areas of consideration when deploying products that contain AI: Legal implications and industry regulation Ethical considerations Change management and organizational/societal implications Case studies will be used extensively to provide real-world examples. MENG 540: Management of High-Tech Industries- The purpose of this course is to empower students to become collaborative, ethical leaders in the globalized, 21st-century workplace. Students learn concepts and practice skills that will enable them to transition from being an engineering sole contributor to managing and leading others as a business professional. Students ### Question: What are some of the key components of the summer internship or industry project offered by the sponsoring organization as described in the text? ### Aswer: Some of the key components of the summer internship or industry project offered by the sponsoring organization as described in the text are: 1. Designing a solution to an authentic opportunity offered by the sponsoring organization 2. Gaining industry experience through the internship or industry project 3. Working on a real-world project that involves applying AI and machine learning technologies to solve practical problems 4. Collaborating with peers and faculty members during the project 5. Presenting the final deliverables to a sponsor panel or external review panel 6. Receiving guidance from Duke faculty members throughout the project 7. Engaging directly with representatives from the company partner organization 8. Submitting a substantive assessment of the internship or project experience via a written report and/or oral presentation 9. Incorporating feedback from industry professionals during the industry seminar series These components provide students with hands-on experience in applying AI and machine learning technologies in a real\""]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["resp"]},{"cell_type":"code","execution_count":54,"metadata":{"execution":{"iopub.execute_input":"2024-04-15T01:58:15.441509Z","iopub.status.busy":"2024-04-15T01:58:15.441092Z","iopub.status.idle":"2024-04-15T01:58:15.461283Z","shell.execute_reply":"2024-04-15T01:58:15.460652Z","shell.execute_reply.started":"2024-04-15T01:58:15.441477Z"},"trusted":true},"outputs":[],"source":["from typing import Any, Dict, List\n","\n","import torch\n","\n","import transformers\n","\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","\n","dtype = torch.bfloat16 if torch.cuda.get_device_capability()[0] == 8 else torch.float16\n","\n","class EndpointHandler:\n","    def __init__(self, path=\"\"):\n","        tokenizer = AutoTokenizer.from_pretrained(path, trust_remote_code = True)\n","        model = AutoModelForCausalLM.from_pretrained(\n","            path,\n","            return_dict = True,\n","            device_map = \"auto\",\n","            load_in_8bit = True,\n","            torch_dtype = dtype,\n","            trust_remote_code = True,\n","        )\n","        \n","        gen_config = model.generation_config\n","        gen_config.max_new_tokens = 100\n","        gen_config.temperature = 0\n","        gen_config.num_return_sequences = 1\n","        gen_config.pad_token_id = tokenizer.eos_token_id\n","        gen_config.eos_token_id = tokenizer.eos_token_id\n","        \n","        self.generation_config = gen_config\n","        \n","        self.pipeline = transformers.pipeline(\n","            'text-generation', model=model, tokenizer=tokenizer\n","        )\n","       \n","     \n","      \n","    def __call__(self, data: Dict[dict, Any]) -> Dict[str, Any]:\n","        question = data.pop(\"question\", data)\n","        \n","        context = data.pop(\"context\", None)\n","        \n","        temp = data.pop(\"temp\", None)\n","        \n","        max_tokens = data.pop(\"max_tokens\", None)\n","        \n","        bos_token = \"<s>\"\n","\n","        original_system_message = \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\"\n","\n","        system_message = \"Use the provided context followed by a question to answer it.\"\n","\n","        full_prompt = f\"\"\"<s>### Instruction:\n","        {system_message}\n","\n","        ### Context:\n","        {context}\n","\n","\n","        ### Question:\n","\n","        {question}\n","\n","\n","        ### Answer: \n","        \"\"\"\n","\n","        full_prompt = \" \".join(full_prompt.split())\n","        \n","        self.generation_config.max_new_tokens = max_tokens\n","        self.generation_config.temperature = temp\n","        \n","        result = self.pipeline(full_prompt, generation_config = self.generation_config)[0]['generated_text']\n","               \n","        match = re.search(r'### Answer:(.*?)###', result, re.DOTALL)\n","        \n","        if match:\n","            result =  match.group(1).strip()\n","            \n","        pattern = r\"### Answer:(.*)\"\n","\n","        match = re.search(pattern, result)\n","        \n","        if match:\n","            result = match.group(1).strip()      \n","        \n","        return result"]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2024-04-15T01:58:18.524607Z","iopub.status.busy":"2024-04-15T01:58:18.523889Z","iopub.status.idle":"2024-04-15T01:58:23.003284Z","shell.execute_reply":"2024-04-15T01:58:23.002396Z","shell.execute_reply.started":"2024-04-15T01:58:18.524573Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n","Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n","/opt/conda/lib/python3.10/site-packages/transformers/quantizers/auto.py:159: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n","  warnings.warn(warning_msg)\n"]}],"source":["MODEL_ID = \"suneeln-duke/dukebot-qac-v1-merged\"\n","\n","my_handler = EndpointHandler(path=MODEL_ID)"]},{"cell_type":"code","execution_count":56,"metadata":{"execution":{"iopub.execute_input":"2024-04-15T01:58:24.969763Z","iopub.status.busy":"2024-04-15T01:58:24.969394Z","iopub.status.idle":"2024-04-15T01:58:24.976939Z","shell.execute_reply":"2024-04-15T01:58:24.976178Z","shell.execute_reply.started":"2024-04-15T01:58:24.969734Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'What are some of the key components of the summer internship or industry project offered by the sponsoring organization as described in the text?'"]},"execution_count":56,"metadata":{},"output_type":"execute_result"}],"source":["sample['Question']"]},{"cell_type":"code","execution_count":57,"metadata":{"execution":{"iopub.execute_input":"2024-04-15T01:58:46.631258Z","iopub.status.busy":"2024-04-15T01:58:46.630445Z","iopub.status.idle":"2024-04-15T01:59:19.949631Z","shell.execute_reply":"2024-04-15T01:59:19.948804Z","shell.execute_reply.started":"2024-04-15T01:58:46.631229Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]}],"source":["%%time\n","import re\n","payload = {\n","    \n","    \"question\": sample['Question'],\n","    \"context\": sample['Context'],\n","    \"max_tokens\": 250,\n","    \"temp\": 0.6\n","    \n","}\n","\n","prediction = my_handler(payload)"]},{"cell_type":"code","execution_count":58,"metadata":{"execution":{"iopub.execute_input":"2024-04-15T01:59:21.629822Z","iopub.status.busy":"2024-04-15T01:59:21.629085Z","iopub.status.idle":"2024-04-15T01:59:21.636985Z","shell.execute_reply":"2024-04-15T01:59:21.636179Z","shell.execute_reply.started":"2024-04-15T01:59:21.629787Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'The summer internship or industry project offered by the sponsoring organization in the Duke Artificial Intelligence Master of Engineering Program includes the following key components: 1. Designing a solution to an authentic opportunity offered by the sponsoring organization: Students are tasked with developing a solution to a real-world problem or challenge presented by the organization. This project allows students to apply their technical AI/ML skills and product development knowledge to solve a practical business problem. 2. Gaining industry experience: The internship or industry project provides students with valuable hands-on experience in the field of artificial intelligence, allowing them to work directly with industry professionals and gain insights into the real-world applications of AI technologies. 3. Professional development: The internship or industry project is an opportunity for students to develop their professional skills, such as communication, teamwork, and problem-solving, in a real-world setting. This experience can help students prepare for future career opportunities in the field of AI. Overall, the summer internship or industry project offers students a chance to apply their academic knowledge in a practical setting, gain industry experience, and develop their professional skills, making it a crucial component of the Duke Artificial Intelligence Master of Engineering Program.'"]},"execution_count":58,"metadata":{},"output_type":"execute_result"}],"source":["prediction"]},{"cell_type":"code","execution_count":83,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T20:58:56.870954Z","iopub.status.busy":"2024-04-12T20:58:56.870449Z","iopub.status.idle":"2024-04-12T20:58:56.879024Z","shell.execute_reply":"2024-04-12T20:58:56.877682Z","shell.execute_reply.started":"2024-04-12T20:58:56.870916Z"},"trusted":true},"outputs":[],"source":["import re\n","\n","def extract_response(text):\n","    match = re.search(r'### Response:(.*?)###', text, re.DOTALL)\n","    if match:\n","        return match.group(1).strip()\n","    else:\n","        return None"]},{"cell_type":"code","execution_count":94,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T21:28:34.937315Z","iopub.status.busy":"2024-04-12T21:28:34.936720Z","iopub.status.idle":"2024-04-12T21:28:34.946164Z","shell.execute_reply":"2024-04-12T21:28:34.945128Z","shell.execute_reply.started":"2024-04-12T21:28:34.937276Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'Denver Broncos Which NFL team represented the NFC at Super Bowl 50?'"]},"execution_count":94,"metadata":{},"output_type":"execute_result"}],"source":["extract_response(prediction[0]['generated_text'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30683,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":4}
